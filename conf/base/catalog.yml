# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# An example data set definition can look as follows:
#
#bikes:
#  type: pandas.CSVDataset
#  filepath: "data/01_raw/bikes.csv"
#
#weather:
#  type: spark.SparkDataset
#  filepath: s3a://your_bucket/data/01_raw/weather*
#  file_format: csv
#  credentials: dev_s3
#  load_args:
#    header: True
#    inferSchema: True
#  save_args:
#    sep: '|'
#    header: True
#
#scooters:
#  type: pandas.SQLTableDataset
#  credentials: scooters_credentials
#  table_name: scooters
#  load_args:
#    index_col: ['name']
#    columns: ['name', 'gear']
#  save_args:
#    if_exists: 'replace'
#    # if_exists: 'fail'
#    # if_exists: 'append'
#
# The Data Catalog supports being able to reference the same file using two different Dataset implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://kedro.readthedocs.io/en/stable/data/data_catalog.html

credit_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/credit_data.csv

score_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/credit_data.csv

credit_data_with_removed_columns:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/credit_data_with_removed_columns.pq

X_train_balanced:
  type: pandas.ParquetDataset
  filepath: data/05_model_input/X_train_balanced.pq

#Y_train_balanced:
#  type: pandas.CSVDataSet
#  filepath: data/05_model_input/Y_train_balanced.pq

X_test_prepared:
  type: pandas.ParquetDataset
  filepath: data/05_model_input/X_test_prepared.pq

one_hot_encoder:
  type: pickle.PickleDataset
  filepath: data/06_models/one_hot_encoder.pickle
  versioned: true

std_scaler:
  type: pickle.PickleDataset
  filepath: data/06_models/std_scaler.pickle
  versioned: true

#best_parameters:
#  type: pandas.JSONDataSet
#  filepath: data/07_model_output/best_parameters.json

model:
  type: pickle.PickleDataset
  filepath: data/06_models/model.pickle
  versioned: true

score_result:
  type: pandas.CSVDataset
  filepath: data/07_model_output/score_result.csv

selected_hyperparamters:
  type: pandas.JSONDataset
  filepath: data/08_reporting/selected_hyperparamters.json
  versioned: true

#Y_predicted:
#  type: pandas.CSVDataSet
#  filepath: data/07_model_output/Y_predicted.pq
#  versioned: true

confusion_matrix:
  type: matplotlib.MatplotlibWriter
  filepath: data/08_reporting/confusion_matrix.png
  versioned: true

metrics:
  type: pandas.JSONDataset
  filepath: data/08_reporting/metrics.json
  versioned: true

#
#regressor:
#  type: pickle.PickleDataset
#  filepath: data/06_models/regressor.pickle
#  versioned: true
#
#metrics:
#  type: tracking.MetricsDataset
#  filepath: data/09_tracking/metrics.json
#
#companies_columns:
#  type: tracking.JSONDataset
#  filepath: data/09_tracking/companies_columns.json
#
#shuttle_passenger_capacity_plot_exp:
#  type: plotly.PlotlyDataset
#  filepath: data/08_reporting/shuttle_passenger_capacity_plot_exp.json
#  versioned: true
#  plotly_args:
#    type: bar
#    fig:
#      x: shuttle_type
#      y: passenger_capacity
#      orientation: h
#    layout:
#      xaxis_title: Shuttles
#      yaxis_title: Average passenger capacity
#      title: Shuttle Passenger capacity
#
#shuttle_passenger_capacity_plot_go:
#  type: plotly.JSONDataset
#  filepath: data/08_reporting/shuttle_passenger_capacity_plot_go.json
#  versioned: true
#
#dummy_confusion_matrix:
#  type: matplotlib.MatplotlibWriter
#  filepath: data/08_reporting/dummy_confusion_matrix.png
#  versioned: true
